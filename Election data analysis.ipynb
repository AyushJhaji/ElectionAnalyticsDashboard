{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbYUpoK1y4fH",
        "outputId": "70913766-6ea1-4bd7-9316-aea03346fa00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1373915269.py:8: DtypeWarning: Columns (17,36,37,38,39,40,41,42,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv('All_States_GE.csv')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Shape: (91669, 45)\n",
            "\n",
            "Column Names:\n",
            "['State_Name', 'Assembly_No', 'Constituency_No', 'Year', 'month', 'Poll_No', 'DelimID', 'Position', 'Candidate', 'Sex', 'Party', 'Votes', 'Candidate_Type', 'Valid_Votes', 'Electors', 'Constituency_Name', 'Constituency_Type', 'Sub_Region', 'N_Cand', 'Turnout_Percentage', 'Vote_Share_Percentage', 'Deposit_Lost', 'Margin', 'Margin_Percentage', 'ENOP', 'pid', 'Party_Type_TCPD', 'Party_ID', 'last_poll', 'Contested', 'Last_Party', 'Last_Party_ID', 'Last_Constituency_Name', 'Same_Constituency', 'Same_Party', 'No_Terms', 'Turncoat', 'Incumbent', 'Recontest', 'MyNeta_education', 'TCPD_Prof_Main', 'TCPD_Prof_Main_Desc', 'TCPD_Prof_Second', 'TCPD_Prof_Second_Desc', 'Election_Type']\n",
            "\n",
            "Data Types:\n",
            "State_Name                 object\n",
            "Assembly_No                 int64\n",
            "Constituency_No             int64\n",
            "Year                        int64\n",
            "month                     float64\n",
            "Poll_No                     int64\n",
            "DelimID                     int64\n",
            "Position                    int64\n",
            "Candidate                  object\n",
            "Sex                        object\n",
            "Party                      object\n",
            "Votes                     float64\n",
            "Candidate_Type             object\n",
            "Valid_Votes                 int64\n",
            "Electors                  float64\n",
            "Constituency_Name          object\n",
            "Constituency_Type          object\n",
            "Sub_Region                 object\n",
            "N_Cand                      int64\n",
            "Turnout_Percentage        float64\n",
            "Vote_Share_Percentage     float64\n",
            "Deposit_Lost               object\n",
            "Margin                    float64\n",
            "Margin_Percentage         float64\n",
            "ENOP                      float64\n",
            "pid                        object\n",
            "Party_Type_TCPD            object\n",
            "Party_ID                  float64\n",
            "last_poll                    bool\n",
            "Contested                 float64\n",
            "Last_Party                 object\n",
            "Last_Party_ID             float64\n",
            "Last_Constituency_Name     object\n",
            "Same_Constituency          object\n",
            "Same_Party                 object\n",
            "No_Terms                  float64\n",
            "Turncoat                   object\n",
            "Incumbent                  object\n",
            "Recontest                  object\n",
            "MyNeta_education           object\n",
            "TCPD_Prof_Main             object\n",
            "TCPD_Prof_Main_Desc        object\n",
            "TCPD_Prof_Second           object\n",
            "TCPD_Prof_Second_Desc      object\n",
            "Election_Type              object\n",
            "dtype: object\n",
            "\n",
            "First few rows:\n",
            "                  State_Name  Assembly_No  Constituency_No  Year  month  \\\n",
            "0  Andaman_&_Nicobar_Islands           17                1  2019    4.0   \n",
            "1  Andaman_&_Nicobar_Islands           17                1  2019    4.0   \n",
            "2  Andaman_&_Nicobar_Islands           17                1  2019    4.0   \n",
            "\n",
            "   Poll_No  DelimID  Position              Candidate Sex  ... No_Terms  \\\n",
            "0        0        4         1     KULDEEP RAI SHARMA   M  ...      1.0   \n",
            "1        0        4         2           VISHAL JOLLY   M  ...      0.0   \n",
            "2        0        4         3  PARITOSH KUMAR HALDAR   M  ...      0.0   \n",
            "\n",
            "   Turncoat Incumbent  Recontest       MyNeta_education  \\\n",
            "0     False     False       True  Graduate Professional   \n",
            "1     False     False      False  Graduate Professional   \n",
            "2     False     False      False          Post Graduate   \n",
            "\n",
            "                       TCPD_Prof_Main TCPD_Prof_Main_Desc TCPD_Prof_Second  \\\n",
            "0                            Business                 NaN      Social Work   \n",
            "1  Liberal Profession or Professional              Lawyer              NaN   \n",
            "2                         Agriculture                 NaN              NaN   \n",
            "\n",
            "   TCPD_Prof_Second_Desc            Election_Type  \n",
            "0                    NaN  Lok Sabha Election (GE)  \n",
            "1                    NaN  Lok Sabha Election (GE)  \n",
            "2                    NaN  Lok Sabha Election (GE)  \n",
            "\n",
            "[3 rows x 45 columns]\n",
            "\n",
            "Missing values summary:\n",
            "State_Name                    0\n",
            "Assembly_No                   0\n",
            "Constituency_No               0\n",
            "Year                          0\n",
            "month                      3079\n",
            "Poll_No                       0\n",
            "DelimID                       0\n",
            "Position                      0\n",
            "Candidate                     0\n",
            "Sex                        2203\n",
            "Party                        21\n",
            "Votes                         4\n",
            "Candidate_Type            61690\n",
            "Valid_Votes                   0\n",
            "Electors                     20\n",
            "Constituency_Name             0\n",
            "Constituency_Type             0\n",
            "Sub_Region                87799\n",
            "N_Cand                        0\n",
            "Turnout_Percentage           20\n",
            "Vote_Share_Percentage        20\n",
            "Deposit_Lost               1107\n",
            "Margin                        1\n",
            "Margin_Percentage            20\n",
            "ENOP                         20\n",
            "pid                        1107\n",
            "Party_Type_TCPD             275\n",
            "Party_ID                    234\n",
            "last_poll                     0\n",
            "Contested                  1107\n",
            "Last_Party                73862\n",
            "Last_Party_ID             73864\n",
            "Last_Constituency_Name    73862\n",
            "Same_Constituency         73853\n",
            "Same_Party                73853\n",
            "No_Terms                   1107\n",
            "Turncoat                   1107\n",
            "Incumbent                  1107\n",
            "Recontest                  1107\n",
            "MyNeta_education          66547\n",
            "TCPD_Prof_Main            65415\n",
            "TCPD_Prof_Main_Desc       85686\n",
            "TCPD_Prof_Second          89116\n",
            "TCPD_Prof_Second_Desc     90988\n",
            "Election_Type                 0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sqlite3\n",
        "from sqlalchemy import create_engine\n",
        "import re\n",
        "\n",
        "# Read the CSV file to examine the structure\n",
        "df = pd.read_csv('All_States_GE.csv')\n",
        "\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nColumn Names:\")\n",
        "print(df.columns.tolist())\n",
        "print(\"\\nData Types:\")\n",
        "print(df.dtypes)\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head(3))\n",
        "print(\"\\nMissing values summary:\")\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Complete Data Preparation Code**"
      ],
      "metadata": {
        "id": "_mq1wxBAzvqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sqlite3\n",
        "from sqlalchemy import create_engine\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "def clean_and_prepare_data():\n",
        "    \"\"\"\n",
        "    Complete data preparation pipeline for election data\n",
        "    \"\"\"\n",
        "    print(\"Starting data preparation...\")\n",
        "\n",
        "    # Read the CSV with proper dtype handling\n",
        "    df = pd.read_csv('All_States_GE.csv', low_memory=False)\n",
        "\n",
        "    print(f\"Original dataset shape: {df.shape}\")\n",
        "\n",
        "    # 1. DATA CLEANING\n",
        "\n",
        "    # Handle mixed types by converting to appropriate types\n",
        "    df['month'] = pd.to_numeric(df['month'], errors='coerce')\n",
        "    df['Votes'] = pd.to_numeric(df['Votes'], errors='coerce')\n",
        "    df['Electors'] = pd.to_numeric(df['Electors'], errors='coerce')\n",
        "    df['Party_ID'] = pd.to_numeric(df['Party_ID'], errors='coerce')\n",
        "    df['Last_Party_ID'] = pd.to_numeric(df['Last_Party_ID'], errors='coerce')\n",
        "    df['No_Terms'] = pd.to_numeric(df['No_Terms'], errors='coerce')\n",
        "\n",
        "    # Convert boolean columns properly\n",
        "    bool_columns = ['last_poll', 'Same_Constituency', 'Same_Party', 'Turncoat', 'Incumbent', 'Recontest']\n",
        "    for col in bool_columns:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].astype(str).str.lower().replace({\n",
        "                'true': True, 'false': False, 'nan': False\n",
        "            }).fillna(False).astype(bool)\n",
        "\n",
        "    # 2. HANDLE MISSING VALUES\n",
        "\n",
        "    # Numerical columns - fill with 0 or median\n",
        "    numerical_cols = ['month', 'Votes', 'Electors', 'Party_ID', 'Last_Party_ID',\n",
        "                        'No_Terms', 'Margin', 'Margin_Percentage', 'ENOP']\n",
        "    for col in numerical_cols:\n",
        "        if col in df.columns:\n",
        "            if col in ['Votes', 'Margin']:\n",
        "                df[col] = df[col].fillna(0)\n",
        "            else:\n",
        "                df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "    # Categorical columns - fill with appropriate values\n",
        "    df['Sex'] = df['Sex'].fillna('Unknown')\n",
        "    df['Party'] = df['Party'].fillna('IND')  # Assume independent if missing\n",
        "    df['Candidate_Type'] = df['Candidate_Type'].fillna('GEN')\n",
        "    df['Deposit_Lost'] = df['Deposit_Lost'].fillna('no')\n",
        "    df['Party_Type_TCPD'] = df['Party_Type_TCPD'].fillna('Unknown')\n",
        "\n",
        "    # Text columns - fill with 'Not Available'\n",
        "    text_cols = ['Sub_Region', 'Last_Party', 'Last_Constituency_Name',\n",
        "                    'MyNeta_education', 'TCPD_Prof_Main', 'TCPD_Prof_Main_Desc',\n",
        "                        'TCPD_Prof_Second', 'TCPD_Prof_Second_Desc']\n",
        "    for col in text_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].fillna('Not Available')\n",
        "\n",
        "    # 3. DATA VALIDATION AND CONSISTENCY CHECKS\n",
        "\n",
        "    # Ensure vote percentages are between 0-100\n",
        "    percentage_cols = ['Turnout_Percentage', 'Vote_Share_Percentage', 'Margin_Percentage']\n",
        "    for col in percentage_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].clip(0, 100)\n",
        "\n",
        "    # Clean candidate names\n",
        "    df['Candidate'] = df['Candidate'].str.strip().str.title()\n",
        "\n",
        "    # Clean party names\n",
        "    df['Party'] = df['Party'].str.strip()\n",
        "\n",
        "    # Ensure valid years\n",
        "    df['Year'] = df['Year'].clip(1950, 2024)\n",
        "\n",
        "    # 4. CREATE DERIVED COLUMNS FOR ANALYSIS\n",
        "\n",
        "    # Create winner flag\n",
        "    df['Is_Winner'] = df['Position'] == 1\n",
        "\n",
        "    # Create margin categories\n",
        "    conditions = [\n",
        "        df['Margin_Percentage'] < 5,\n",
        "        (df['Margin_Percentage'] >= 5) & (df['Margin_Percentage'] < 10),\n",
        "        df['Margin_Percentage'] >= 10\n",
        "    ]\n",
        "    choices = ['Close Contest', 'Moderate Margin', 'Large Margin']\n",
        "    df['Margin_Category'] = np.select(conditions, choices, default='Unknown')\n",
        "\n",
        "    # Create experience categories\n",
        "    df['Experience_Level'] = pd.cut(df['No_Terms'],\n",
        "                                    bins=[-1, 0, 2, 5, 100],\n",
        "                                    labels=['New', 'Experienced', 'Veteran', 'Senior'])\n",
        "\n",
        "    # Party size categories based on votes\n",
        "    df['Party_Size'] = pd.cut(df['Votes'],\n",
        "                                bins=[0, 10000, 50000, 200000, float('inf')],\n",
        "                                labels=['Small', 'Medium', 'Large', 'Very Large'])\n",
        "\n",
        "    print(f\"Cleaned dataset shape: {df.shape}\")\n",
        "    print(\"Missing values after cleaning:\")\n",
        "    print(df.isnull().sum().sum())  # Total missing values\n",
        "\n",
        "    return df\n",
        "\n",
        "def create_database_schema(df):\n",
        "    \"\"\"\n",
        "    Create SQLite database with optimized schema\n",
        "    \"\"\"\n",
        "    print(\"\\nCreating database schema...\")\n",
        "\n",
        "    # Connect to SQLite database (creates if doesn't exist)\n",
        "    conn = sqlite3.connect('election_data.db')\n",
        "\n",
        "    # 1. MAIN ELECTION RESULTS TABLE\n",
        "    df.to_sql('election_results', conn, if_exists='replace', index=False)\n",
        "\n",
        "    # 2. CREATE DIMENSION TABLES FOR BETTER NORMALIZATION\n",
        "\n",
        "    # Party dimension table\n",
        "    party_dim = df[['Party', 'Party_Type_TCPD', 'Party_ID']].drop_duplicates().reset_index(drop=True)\n",
        "    party_dim['party_dim_id'] = party_dim.index + 1\n",
        "    party_dim.to_sql('party_dimension', conn, if_exists='replace', index=False)\n",
        "\n",
        "    # Candidate dimension table\n",
        "    candidate_dim = df[['Candidate', 'Sex', 'MyNeta_education',\n",
        "                        'TCPD_Prof_Main', 'TCPD_Prof_Main_Desc',\n",
        "                        'TCPD_Prof_Second', 'TCPD_Prof_Second_Desc']].drop_duplicates().reset_index(drop=True)\n",
        "    candidate_dim['candidate_dim_id'] = candidate_dim.index + 1\n",
        "    candidate_dim.to_sql('candidate_dimension', conn, if_exists='replace', index=False)\n",
        "\n",
        "    # Constituency dimension table\n",
        "    constituency_dim = df[['State_Name', 'Constituency_Name', 'Constituency_Type',\n",
        "                            'Sub_Region', 'Assembly_No', 'Constituency_No']].drop_duplicates().reset_index(drop=True)\n",
        "    constituency_dim['constituency_dim_id'] = constituency_dim.index + 1\n",
        "    constituency_dim.to_sql('constituency_dimension', conn, if_exists='replace', index=False)\n",
        "\n",
        "    # 3. CREATE AGGREGATION TABLES FOR FAST QUERYING\n",
        "\n",
        "    # Party performance summary\n",
        "    party_performance_query = \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS party_performance_summary AS\n",
        "            SELECT\n",
        "                    Party,\n",
        "                    COUNT(*) as total_candidates,\n",
        "                    SUM(CASE WHEN Position = 1 THEN 1 ELSE 0 END) as seats_won,\n",
        "                    AVG(Vote_Share_Percentage) as avg_vote_share,\n",
        "                    SUM(Votes) as total_votes,\n",
        "                    SUM(CASE WHEN Deposit_Lost = 'no' THEN 1 ELSE 0 END) as deposits_saved\n",
        "                FROM election_results\n",
        "                GROUP BY Party\n",
        "                ORDER BY seats_won DESC, total_votes DESC\n",
        "            \"\"\"\n",
        "    conn.execute(party_performance_query)\n",
        "\n",
        "    # State-wise summary\n",
        "    state_summary_query = \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS state_election_summary AS\n",
        "            SELECT\n",
        "                    State_Name,\n",
        "                    COUNT(DISTINCT Constituency_Name) as total_constituencies,\n",
        "                    COUNT(*) as total_candidates,\n",
        "                    AVG(Turnout_Percentage) as avg_turnout,\n",
        "                    SUM(Valid_Votes) as total_valid_votes,\n",
        "                    MAX(Electors) as total_electors\n",
        "                FROM election_results\n",
        "                GROUP BY State_Name\n",
        "                ORDER BY total_constituencies DESC\n",
        "            \"\"\"\n",
        "    conn.execute(state_summary_query)\n",
        "\n",
        "    # Candidate experience analysis\n",
        "    candidate_experience_query = \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS candidate_experience_analysis AS\n",
        "            SELECT\n",
        "                Experience_Level,\n",
        "                candidate_count,\n",
        "                winners,\n",
        "                ROUND(100.0 * winners / candidate_count, 2) as win_rate\n",
        "            FROM (\n",
        "                SELECT\n",
        "                    Experience_Level,\n",
        "                    COUNT(*) as candidate_count,\n",
        "                    SUM(CASE WHEN Position = 1 THEN 1 ELSE 0 END) as winners,\n",
        "                    AVG(No_Terms) as avg_terms\n",
        "                FROM election_results\n",
        "                GROUP BY Experience_Level\n",
        "            )\n",
        "            ORDER BY win_rate DESC\n",
        "        \"\"\"\n",
        "    conn.execute(candidate_experience_query)\n",
        "\n",
        "    # Close contest analysis\n",
        "    close_contest_query = \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS close_contest_analysis AS\n",
        "            SELECT\n",
        "                    State_Name,\n",
        "                    Constituency_Name,\n",
        "                    Margin_Category,\n",
        "                    COUNT(*) as contest_count,\n",
        "                    AVG(Margin_Percentage) as avg_margin\n",
        "                FROM election_results\n",
        "                WHERE Position = 1  -- Only winners\n",
        "                GROUP BY State_Name, Constituency_Name, Margin_Category\n",
        "                ORDER BY State_Name, contest_count DESC\n",
        "            \"\"\"\n",
        "    conn.execute(close_contest_query)\n",
        "\n",
        "    # 4. CREATE INDEXES FOR PERFORMANCE\n",
        "    indexes = [\n",
        "        \"CREATE INDEX IF NOT EXISTS idx_party ON election_results(Party)\",\n",
        "        \"CREATE INDEX IF NOT EXISTS idx_state ON election_results(State_Name)\",\n",
        "        \"CREATE INDEX IF NOT EXISTS idx_constituency ON election_results(Constituency_Name)\",\n",
        "        \"CREATE INDEX IF NOT EXISTS idx_year ON election_results(Year)\",\n",
        "        \"CREATE INDEX IF NOT EXISTS idx_position ON election_results(Position)\",\n",
        "        \"CREATE INDEX IF NOT EXISTS idx_winner ON election_results(Is_Winner)\"\n",
        "    ]\n",
        "\n",
        "    for index_query in indexes:\n",
        "        conn.execute(index_query)\n",
        "\n",
        "    # Verify table creation\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "    tables = cursor.fetchall()\n",
        "\n",
        "    print(\"Created tables:\")\n",
        "    for table in tables:\n",
        "        print(f\" - {table[0]}\")\n",
        "\n",
        "    # Show sample data from main table\n",
        "    sample_data = pd.read_sql(\"SELECT * FROM election_results LIMIT 3\", conn)\n",
        "    print(\"\\nSample data from main table:\")\n",
        "    print(sample_data[['State_Name', 'Candidate', 'Party', 'Votes', 'Position']])\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "    print(\"\\nDatabase creation completed successfully!\")\n",
        "\n",
        "def generate_data_quality_report(df):\n",
        "    \"\"\"\n",
        "    Generate comprehensive data quality report\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"DATA QUALITY REPORT\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    print(f\"Total Records: {len(df):,}\")\n",
        "    print(f\"Total Columns: {len(df.columns)}\")\n",
        "    print(f\"Total Missing Values: {df.isnull().sum().sum()}\")\n",
        "\n",
        "    # Data completeness\n",
        "    completeness = (1 - df.isnull().sum() / len(df)) * 100\n",
        "    print(\"\\nColumn Completeness (%):\")\n",
        "    for col, comp in completeness.items():\n",
        "        print(f\"  {col}: {comp:.1f}%\")\n",
        "\n",
        "    # Unique values\n",
        "    print(f\"\\nUnique States: {df['State_Name'].nunique()}\")\n",
        "    print(f\"Unique Parties: {df['Party'].nunique()}\")\n",
        "    print(f\"Unique Constituencies: {df['Constituency_Name'].nunique()}\")\n",
        "\n",
        "    # Election years\n",
        "    print(f\"\\nElection Years: {sorted(df['Year'].unique())}\")\n",
        "\n",
        "    # Winner statistics\n",
        "    winners = df[df['Position'] == 1]\n",
        "    print(f\"\\nTotal Winners: {len(winners):,}\")\n",
        "    print(f\"Female Winners: {len(winners[winners['Sex'] == 'F']):,}\")\n",
        "    print(f\"Male Winners: {len(winners[winners['Sex'] == 'M']):,}\")\n",
        "\n",
        "def create_query_examples():\n",
        "    \"\"\"\n",
        "    Create example queries for common analysis\n",
        "    \"\"\"\n",
        "    conn = sqlite3.connect('election_data.db')\n",
        "\n",
        "    queries = {\n",
        "        \"Top 10 parties by seats won\": \"\"\"\n",
        "            SELECT Party, seats_won, total_votes\n",
        "            FROM party_performance_summary\n",
        "            ORDER BY seats_won DESC\n",
        "            LIMIT 10\n",
        "            \"\"\",\n",
        "\n",
        "        \"States with highest turnout\": \"\"\"\n",
        "            SELECT State_Name, avg_turnout, total_constituencies\n",
        "            FROM state_election_summary\n",
        "            ORDER BY avg_turnout DESC\n",
        "            LIMIT 10\n",
        "            \"\"\",\n",
        "\n",
        "        \"Close contests by state\": \"\"\"\n",
        "            SELECT State_Name, Margin_Category, COUNT(*) as contest_count\n",
        "            FROM close_contest_analysis\n",
        "            GROUP BY State_Name, Margin_Category\n",
        "            ORDER BY contest_count DESC\n",
        "            \"\"\",\n",
        "\n",
        "        \"Candidate experience analysis\": \"\"\"\n",
        "            SELECT Experience_Level, candidate_count, winners,\n",
        "            ROUND(100.0 * winners / candidate_count, 2) as win_rate\n",
        "            FROM candidate_experience_analysis\n",
        "            ORDER BY win_rate DESC\n",
        "            \"\"\"\n",
        "    }\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"QUERY EXAMPLES\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    for query_name, query in queries.items():\n",
        "        print(f\"\\n{query_name}:\")\n",
        "        try:\n",
        "            result = pd.read_sql(query, conn)\n",
        "            print(result.head())\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "# MAIN EXECUTION\n",
        "if __name__ == \"__main__\":\n",
        "    # Step 1: Clean and prepare data\n",
        "    cleaned_df = clean_and_prepare_data()\n",
        "\n",
        "    # Step 2: Generate data quality report\n",
        "    generate_data_quality_report(cleaned_df)\n",
        "\n",
        "    # Step 3: Create database and schema\n",
        "    create_database_schema(cleaned_df)\n",
        "\n",
        "    # Step 4: Show query examples\n",
        "    create_query_examples()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"DATA PREPARATION COMPLETED SUCCESSFULLY!\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"Database file: election_data.db\")\n",
        "    print(\"Main table: election_results\")\n",
        "    print(\"Dimension tables: party_dimension, candidate_dimension, constituency_dimension\")\n",
        "    print(\"Aggregation tables: party_performance_summary, state_election_summary, etc.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQ3RhxudzzCr",
        "outputId": "de7b4a42-d56d-40ed-eb49-894181a15f79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting data preparation...\n",
            "Original dataset shape: (91669, 45)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-427313477.py:33: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[col] = df[col].astype(str).str.lower().replace({\n",
            "/tmp/ipython-input-427313477.py:33: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[col] = df[col].astype(str).str.lower().replace({\n",
            "/tmp/ipython-input-427313477.py:33: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[col] = df[col].astype(str).str.lower().replace({\n",
            "/tmp/ipython-input-427313477.py:33: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[col] = df[col].astype(str).str.lower().replace({\n",
            "/tmp/ipython-input-427313477.py:33: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[col] = df[col].astype(str).str.lower().replace({\n",
            "/tmp/ipython-input-427313477.py:33: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[col] = df[col].astype(str).str.lower().replace({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned dataset shape: (91669, 49)\n",
            "Missing values after cleaning:\n",
            "2274\n",
            "\n",
            "==================================================\n",
            "DATA QUALITY REPORT\n",
            "==================================================\n",
            "Total Records: 91,669\n",
            "Total Columns: 49\n",
            "Total Missing Values: 2274\n",
            "\n",
            "Column Completeness (%):\n",
            "  State_Name: 100.0%\n",
            "  Assembly_No: 100.0%\n",
            "  Constituency_No: 100.0%\n",
            "  Year: 100.0%\n",
            "  month: 100.0%\n",
            "  Poll_No: 100.0%\n",
            "  DelimID: 100.0%\n",
            "  Position: 100.0%\n",
            "  Candidate: 100.0%\n",
            "  Sex: 100.0%\n",
            "  Party: 100.0%\n",
            "  Votes: 100.0%\n",
            "  Candidate_Type: 100.0%\n",
            "  Valid_Votes: 100.0%\n",
            "  Electors: 100.0%\n",
            "  Constituency_Name: 100.0%\n",
            "  Constituency_Type: 100.0%\n",
            "  Sub_Region: 100.0%\n",
            "  N_Cand: 100.0%\n",
            "  Turnout_Percentage: 100.0%\n",
            "  Vote_Share_Percentage: 100.0%\n",
            "  Deposit_Lost: 100.0%\n",
            "  Margin: 100.0%\n",
            "  Margin_Percentage: 100.0%\n",
            "  ENOP: 100.0%\n",
            "  pid: 98.8%\n",
            "  Party_Type_TCPD: 100.0%\n",
            "  Party_ID: 100.0%\n",
            "  last_poll: 100.0%\n",
            "  Contested: 98.8%\n",
            "  Last_Party: 100.0%\n",
            "  Last_Party_ID: 100.0%\n",
            "  Last_Constituency_Name: 100.0%\n",
            "  Same_Constituency: 100.0%\n",
            "  Same_Party: 100.0%\n",
            "  No_Terms: 100.0%\n",
            "  Turncoat: 100.0%\n",
            "  Incumbent: 100.0%\n",
            "  Recontest: 100.0%\n",
            "  MyNeta_education: 100.0%\n",
            "  TCPD_Prof_Main: 100.0%\n",
            "  TCPD_Prof_Main_Desc: 100.0%\n",
            "  TCPD_Prof_Second: 100.0%\n",
            "  TCPD_Prof_Second_Desc: 100.0%\n",
            "  Election_Type: 100.0%\n",
            "  Is_Winner: 100.0%\n",
            "  Margin_Category: 100.0%\n",
            "  Experience_Level: 100.0%\n",
            "  Party_Size: 100.0%\n",
            "\n",
            "Unique States: 40\n",
            "Unique Parties: 1614\n",
            "Unique Constituencies: 946\n",
            "\n",
            "Election Years: [np.int64(1962), np.int64(1963), np.int64(1964), np.int64(1965), np.int64(1967), np.int64(1968), np.int64(1969), np.int64(1970), np.int64(1971), np.int64(1972), np.int64(1977), np.int64(1978), np.int64(1979), np.int64(1980), np.int64(1981), np.int64(1982), np.int64(1984), np.int64(1985), np.int64(1986), np.int64(1987), np.int64(1988), np.int64(1989), np.int64(1991), np.int64(1992), np.int64(1993), np.int64(1994), np.int64(1995), np.int64(1996), np.int64(1997), np.int64(1998), np.int64(1999), np.int64(2000), np.int64(2001), np.int64(2002), np.int64(2003), np.int64(2004), np.int64(2005), np.int64(2006), np.int64(2007), np.int64(2008), np.int64(2009), np.int64(2011), np.int64(2012), np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021)]\n",
            "\n",
            "Total Winners: 8,291\n",
            "Female Winners: 674\n",
            "Male Winners: 7,546\n",
            "\n",
            "Creating database schema...\n",
            "Created tables:\n",
            " - party_performance_summary\n",
            " - state_election_summary\n",
            " - candidate_experience_analysis\n",
            " - close_contest_analysis\n",
            " - election_results\n",
            " - party_dimension\n",
            " - candidate_dimension\n",
            " - constituency_dimension\n",
            "\n",
            "Sample data from main table:\n",
            "                  State_Name              Candidate Party    Votes  Position\n",
            "0  Andaman_&_Nicobar_Islands     Kuldeep Rai Sharma   INC  95308.0         1\n",
            "1  Andaman_&_Nicobar_Islands           Vishal Jolly   BJP  93901.0         2\n",
            "2  Andaman_&_Nicobar_Islands  Paritosh Kumar Haldar   IND   5341.0         3\n",
            "\n",
            "Database creation completed successfully!\n",
            "\n",
            "==================================================\n",
            "QUERY EXAMPLES\n",
            "==================================================\n",
            "\n",
            "Top 10 parties by seats won:\n",
            "    Party  seats_won   total_votes\n",
            "0     INC       2942  1.364944e+09\n",
            "1     BJP       1603  9.488584e+08\n",
            "2     CPM        370  2.232780e+08\n",
            "3  INC(I)        367  8.845586e+07\n",
            "4     BLD        295  7.806283e+07\n",
            "\n",
            "States with highest turnout:\n",
            "                             State_Name  avg_turnout  total_constituencies\n",
            "0                           Lakshadweep    82.528723                     3\n",
            "1  Dadra & Nagar Haveli And Daman & Diu    76.590000                     1\n",
            "2                               Tripura    75.784404                     3\n",
            "3                              Nagaland    75.147333                     1\n",
            "4                            Puducherry    74.597312                     2\n",
            "\n",
            "Close contests by state:\n",
            "      State_Name  Margin_Category  contest_count\n",
            "0  Uttar_Pradesh     Large Margin            116\n",
            "1  Uttar_Pradesh    Close Contest            104\n",
            "2  Uttar_Pradesh  Moderate Margin             93\n",
            "3    Maharashtra     Large Margin             91\n",
            "4          Bihar     Large Margin             86\n",
            "\n",
            "Candidate experience analysis:\n",
            "  Experience_Level  candidate_count  winners  win_rate\n",
            "0           Senior              300      230     76.67\n",
            "1          Veteran             2369     1608     67.88\n",
            "2      Experienced             9513     6453     67.83\n",
            "3              New            79487        0      0.00\n",
            "\n",
            "==================================================\n",
            "DATA PREPARATION COMPLETED SUCCESSFULLY!\n",
            "==================================================\n",
            "Database file: election_data.db\n",
            "Main table: election_results\n",
            "Dimension tables: party_dimension, candidate_dimension, constituency_dimension\n",
            "Aggregation tables: party_performance_summary, state_election_summary, etc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae423f4d",
        "outputId": "fefa6ced-b66e-447d-8c26-c03670328bdf"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sqlite3\n",
        "from sqlalchemy import create_engine\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "def clean_and_prepare_data():\n",
        "    \"\"\"\n",
        "    Complete data preparation pipeline for election data\n",
        "    \"\"\"\n",
        "    print(\"Starting data preparation...\")\n",
        "\n",
        "    # Read the CSV with proper dtype handling\n",
        "    df = pd.read_csv('All_States_GE.csv', low_memory=False)\n",
        "\n",
        "    print(f\"Original dataset shape: {df.shape}\")\n",
        "\n",
        "    # 1. DATA CLEANING\n",
        "\n",
        "    # Handle mixed types by converting to appropriate types\n",
        "    df['month'] = pd.to_numeric(df['month'], errors='coerce')\n",
        "    df['Votes'] = pd.to_numeric(df['Votes'], errors='coerce')\n",
        "    df['Electors'] = pd.to_numeric(df['Electors'], errors='coerce')\n",
        "    df['Party_ID'] = pd.to_numeric(df['Party_ID'], errors='coerce')\n",
        "    df['Last_Party_ID'] = pd.to_numeric(df['Last_Party_ID'], errors='coerce')\n",
        "    df['No_Terms'] = pd.to_numeric(df['No_Terms'], errors='coerce')\n",
        "\n",
        "    # Convert boolean columns properly\n",
        "    bool_columns = ['last_poll', 'Same_Constituency', 'Same_Party', 'Turncoat', 'Incumbent', 'Recontest']\n",
        "    for col in bool_columns:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].astype(str).str.lower().replace({\n",
        "                'true': True, 'false': False, 'nan': False\n",
        "            }).fillna(False).astype(bool)\n",
        "\n",
        "    # 2. HANDLE MISSING VALUES\n",
        "\n",
        "    # Numerical columns - fill with 0 or median\n",
        "    numerical_cols = ['month', 'Votes', 'Electors', 'Party_ID', 'Last_Party_ID',\n",
        "                        'No_Terms', 'Margin', 'Margin_Percentage', 'ENOP']\n",
        "    for col in numerical_cols:\n",
        "        if col in df.columns:\n",
        "            if col in ['Votes', 'Margin']:\n",
        "                df[col] = df[col].fillna(0)\n",
        "            else:\n",
        "                df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "    # Categorical columns - fill with appropriate values\n",
        "    df['Sex'] = df['Sex'].fillna('Unknown')\n",
        "    df['Party'] = df['Party'].fillna('IND')  # Assume independent if missing\n",
        "    df['Candidate_Type'] = df['Candidate_Type'].fillna('GEN')\n",
        "    df['Deposit_Lost'] = df['Deposit_Lost'].fillna('no')\n",
        "    df['Party_Type_TCPD'] = df['Party_Type_TCPD'].fillna('Unknown')\n",
        "\n",
        "    # Text columns - fill with 'Not Available'\n",
        "    text_cols = ['Sub_Region', 'Last_Party', 'Last_Constituency_Name',\n",
        "                    'MyNeta_education', 'TCPD_Prof_Main', 'TCPD_Prof_Main_Desc',\n",
        "                        'TCPD_Prof_Second', 'TCPD_Prof_Second_Desc']\n",
        "    for col in text_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].fillna('Not Available')\n",
        "\n",
        "    # 3. DATA VALIDATION AND CONSISTENCY CHECKS\n",
        "\n",
        "    # Ensure vote percentages are between 0-100\n",
        "    percentage_cols = ['Turnout_Percentage', 'Vote_Share_Percentage', 'Margin_Percentage']\n",
        "    for col in percentage_cols:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].clip(0, 100)\n",
        "\n",
        "    # Clean candidate names\n",
        "    df['Candidate'] = df['Candidate'].str.strip().str.title()\n",
        "\n",
        "    # Clean party names\n",
        "    df['Party'] = df['Party'].str.strip()\n",
        "\n",
        "    # Ensure valid years\n",
        "    df['Year'] = df['Year'].clip(1950, 2024)\n",
        "\n",
        "    # 4. CREATE DERIVED COLUMNS FOR ANALYSIS\n",
        "\n",
        "    # Create winner flag\n",
        "    df['Is_Winner'] = df['Position'] == 1\n",
        "\n",
        "    # Create margin categories\n",
        "    conditions = [\n",
        "        df['Margin_Percentage'] < 5,\n",
        "        (df['Margin_Percentage'] >= 5) & (df['Margin_Percentage'] < 10),\n",
        "        df['Margin_Percentage'] >= 10\n",
        "    ]\n",
        "    choices = ['Close Contest', 'Moderate Margin', 'Large Margin']\n",
        "    df['Margin_Category'] = np.select(conditions, choices, default='Unknown')\n",
        "\n",
        "    # Create experience categories\n",
        "    df['Experience_Level'] = pd.cut(df['No_Terms'],\n",
        "                                    bins=[-1, 0, 2, 5, 100],\n",
        "                                    labels=['New', 'Experienced', 'Veteran', 'Senior'])\n",
        "\n",
        "    # Party size categories based on votes\n",
        "    df['Party_Size'] = pd.cut(df['Votes'],\n",
        "                                bins=[0, 10000, 50000, 200000, float('inf')],\n",
        "                                labels=['Small', 'Medium', 'Large', 'Very Large'])\n",
        "\n",
        "    print(f\"Cleaned dataset shape: {df.shape}\")\n",
        "    print(\"Missing values after cleaning:\")\n",
        "    print(df.isnull().sum().sum())  # Total missing values\n",
        "\n",
        "    return df\n",
        "\n",
        "def create_database_schema(df):\n",
        "    \"\"\"\n",
        "    Create SQLite database with optimized schema\n",
        "    \"\"\"\n",
        "    print(\"\\nCreating database schema...\")\n",
        "\n",
        "    # Connect to SQLite database (creates if doesn't exist)\n",
        "    conn = sqlite3.connect('election_data.db')\n",
        "\n",
        "    # 1. MAIN ELECTION RESULTS TABLE\n",
        "    df.to_sql('election_results', conn, if_exists='replace', index=False)\n",
        "\n",
        "    # 2. CREATE DIMENSION TABLES FOR BETTER NORMALIZATION\n",
        "\n",
        "    # Party dimension table\n",
        "    party_dim = df[['Party', 'Party_Type_TCPD', 'Party_ID']].drop_duplicates().reset_index(drop=True)\n",
        "    party_dim['party_dim_id'] = party_dim.index + 1\n",
        "    party_dim.to_sql('party_dimension', conn, if_exists='replace', index=False)\n",
        "\n",
        "    # Candidate dimension table\n",
        "    candidate_dim = df[['Candidate', 'Sex', 'MyNeta_education',\n",
        "                        'TCPD_Prof_Main', 'TCPD_Prof_Main_Desc',\n",
        "                        'TCPD_Prof_Second', 'TCPD_Prof_Second_Desc']].drop_duplicates().reset_index(drop=True)\n",
        "    candidate_dim['candidate_dim_id'] = candidate_dim.index + 1\n",
        "    candidate_dim.to_sql('candidate_dimension', conn, if_exists='replace', index=False)\n",
        "\n",
        "    # Constituency dimension table\n",
        "    constituency_dim = df[['State_Name', 'Constituency_Name', 'Constituency_Type',\n",
        "                            'Sub_Region', 'Assembly_No', 'Constituency_No']].drop_duplicates().reset_index(drop=True)\n",
        "    constituency_dim['constituency_dim_id'] = constituency_dim.index + 1\n",
        "    constituency_dim.to_sql('constituency_dimension', conn, if_exists='replace', index=False)\n",
        "\n",
        "    # 3. CREATE AGGREGATION TABLES FOR FAST QUERYING\n",
        "\n",
        "    # Party performance summary\n",
        "    party_performance_query = \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS party_performance_summary AS\n",
        "            SELECT\n",
        "                    Party,\n",
        "                    COUNT(*) as total_candidates,\n",
        "                    SUM(CASE WHEN Position = 1 THEN 1 ELSE 0 END) as seats_won,\n",
        "                    AVG(Vote_Share_Percentage) as avg_vote_share,\n",
        "                    SUM(Votes) as total_votes,\n",
        "                    SUM(CASE WHEN Deposit_Lost = 'no' THEN 1 ELSE 0 END) as deposits_saved\n",
        "                FROM election_results\n",
        "                GROUP BY Party\n",
        "                ORDER BY seats_won DESC, total_votes DESC\n",
        "            \"\"\"\n",
        "    conn.execute(party_performance_query)\n",
        "\n",
        "    # State-wise summary\n",
        "    state_summary_query = \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS state_election_summary AS\n",
        "            SELECT\n",
        "                    State_Name,\n",
        "                    COUNT(DISTINCT Constituency_Name) as total_constituencies,\n",
        "                    COUNT(*) as total_candidates,\n",
        "                    AVG(Turnout_Percentage) as avg_turnout,\n",
        "                    SUM(Valid_Votes) as total_valid_votes,\n",
        "                    MAX(Electors) as total_electors\n",
        "                FROM election_results\n",
        "                GROUP BY State_Name\n",
        "                ORDER BY total_constituencies DESC\n",
        "            \"\"\"\n",
        "    conn.execute(state_summary_query)\n",
        "\n",
        "    # Candidate experience analysis\n",
        "    candidate_experience_query = \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS candidate_experience_analysis AS\n",
        "            SELECT\n",
        "                Experience_Level,\n",
        "                candidate_count,\n",
        "                winners,\n",
        "                ROUND(100.0 * winners / candidate_count, 2) as win_rate\n",
        "            FROM (\n",
        "                SELECT\n",
        "                    Experience_Level,\n",
        "                    COUNT(*) as candidate_count,\n",
        "                    SUM(CASE WHEN Position = 1 THEN 1 ELSE 0 END) as winners,\n",
        "                    AVG(No_Terms) as avg_terms\n",
        "                FROM election_results\n",
        "                GROUP BY Experience_Level\n",
        "            )\n",
        "            ORDER BY win_rate DESC\n",
        "        \"\"\"\n",
        "    conn.execute(candidate_experience_query)\n",
        "\n",
        "    # Close contest analysis\n",
        "    close_contest_query = \"\"\"\n",
        "        CREATE TABLE IF NOT EXISTS close_contest_analysis AS\n",
        "            SELECT\n",
        "                    State_Name,\n",
        "                    Constituency_Name,\n",
        "                    Margin_Category,\n",
        "                    COUNT(*) as contest_count,\n",
        "                    AVG(Margin_Percentage) as avg_margin\n",
        "                FROM election_results\n",
        "                WHERE Position = 1  -- Only winners\n",
        "                GROUP BY State_Name, Constituency_Name, Margin_Category\n",
        "                ORDER BY State_Name, contest_count DESC\n",
        "            \"\"\"\n",
        "    conn.execute(close_contest_query)\n",
        "\n",
        "    # 4. CREATE INDEXES FOR PERFORMANCE\n",
        "    indexes = [\n",
        "        \"CREATE INDEX IF NOT EXISTS idx_party ON election_results(Party)\",\n",
        "        \"CREATE INDEX IF NOT EXISTS idx_state ON election_results(State_Name)\",\n",
        "        \"CREATE INDEX IF NOT EXISTS idx_constituency ON election_results(Constituency_Name)\",\n",
        "        \"CREATE INDEX IF NOT EXISTS idx_year ON election_results(Year)\",\n",
        "        \"CREATE INDEX IF NOT EXISTS idx_position ON election_results(Position)\",\n",
        "        \"CREATE INDEX IF NOT EXISTS idx_winner ON election_results(Is_Winner)\"\n",
        "    ]\n",
        "\n",
        "    for index_query in indexes:\n",
        "        conn.execute(index_query)\n",
        "\n",
        "    # Verify table creation\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "    tables = cursor.fetchall()\n",
        "\n",
        "    print(\"Created tables:\")\n",
        "    for table in tables:\n",
        "        print(f\" - {table[0]}\")\n",
        "\n",
        "    # Show sample data from main table\n",
        "    sample_data = pd.read_sql(\"SELECT * FROM election_results LIMIT 3\", conn)\n",
        "    print(\"\\nSample data from main table:\")\n",
        "    print(sample_data[['State_Name', 'Candidate', 'Party', 'Votes', 'Position']])\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "    print(\"\\nDatabase creation completed successfully!\")\n",
        "\n",
        "def generate_data_quality_report(df):\n",
        "    \"\"\"\n",
        "    Generate comprehensive data quality report\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"DATA QUALITY REPORT\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    print(f\"Total Records: {len(df):,}\")\n",
        "    print(f\"Total Columns: {len(df.columns)}\")\n",
        "    print(f\"Total Missing Values: {df.isnull().sum().sum()}\")\n",
        "\n",
        "    # Data completeness\n",
        "    completeness = (1 - df.isnull().sum() / len(df)) * 100\n",
        "    print(\"\\nColumn Completeness (%):\")\n",
        "    for col, comp in completeness.items():\n",
        "        print(f\"  {col}: {comp:.1f}%\")\n",
        "\n",
        "    # Unique values\n",
        "    print(f\"\\nUnique States: {df['State_Name'].nunique()}\")\n",
        "    print(f\"Unique Parties: {df['Party'].nunique()}\")\n",
        "    print(f\"Unique Constituencies: {df['Constituency_Name'].nunique()}\")\n",
        "\n",
        "    # Election years\n",
        "    print(f\"\\nElection Years: {sorted(df['Year'].unique())}\")\n",
        "\n",
        "    # Winner statistics\n",
        "    winners = df[df['Position'] == 1]\n",
        "    print(f\"\\nTotal Winners: {len(winners):,}\")\n",
        "    print(f\"Female Winners: {len(winners[winners['Sex'] == 'F']):,}\")\n",
        "    print(f\"Male Winners: {len(winners[winners['Sex'] == 'M']):,}\")\n",
        "\n",
        "def create_query_examples():\n",
        "    \"\"\"\n",
        "    Create example queries for common analysis\n",
        "    \"\"\"\n",
        "    conn = sqlite3.connect('election_data.db')\n",
        "\n",
        "    queries = {\n",
        "        \"Top 10 parties by seats won\": \"\"\"\n",
        "            SELECT Party, seats_won, total_votes\n",
        "            FROM party_performance_summary\n",
        "            ORDER BY seats_won DESC\n",
        "            LIMIT 10\n",
        "            \"\"\",\n",
        "\n",
        "        \"States with highest turnout\": \"\"\"\n",
        "            SELECT State_Name, avg_turnout, total_constituencies\n",
        "            FROM state_election_summary\n",
        "            ORDER BY avg_turnout DESC\n",
        "            LIMIT 10\n",
        "            \"\"\",\n",
        "\n",
        "        \"Close contests by state\": \"\"\"\n",
        "            SELECT State_Name, Margin_Category, COUNT(*) as contest_count\n",
        "            FROM close_contest_analysis\n",
        "            GROUP BY State_Name, Margin_Category\n",
        "            ORDER BY State_Name, contest_count DESC\n",
        "            \"\"\",\n",
        "\n",
        "        \"Candidate experience analysis\": \"\"\"\n",
        "            SELECT Experience_Level, candidate_count, winners,\n",
        "            ROUND(100.0 * winners / candidate_count, 2) as win_rate\n",
        "            FROM candidate_experience_analysis\n",
        "            ORDER BY win_rate DESC\n",
        "            \"\"\"\n",
        "    }\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"QUERY EXAMPLES\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    for query_name, query in queries.items():\n",
        "        print(f\"\\n{query_name}:\")\n",
        "        try:\n",
        "            result = pd.read_sql(query, conn)\n",
        "            print(result.head())\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "# MAIN EXECUTION\n",
        "if __name__ == \"__main__\":\n",
        "    # Step 1: Clean and prepare data\n",
        "    cleaned_df = clean_and_prepare_data()\n",
        "\n",
        "    # Step 2: Generate data quality report\n",
        "    generate_data_quality_report(cleaned_df)\n",
        "\n",
        "    # Step 3: Create database and schema\n",
        "    create_database_schema(cleaned_df)\n",
        "\n",
        "    # Step 4: Show query examples\n",
        "    create_query_examples()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"DATA PREPARATION COMPLETED SUCCESSFULLY!\")\n",
        "    print(\"=\"*50)\n",
        "    print(\"Database file: election_data.db\")\n",
        "    print(\"Main table: election_results\")\n",
        "    print(\"Dimension tables: party_dimension, candidate_dimension, constituency_dimension\")\n",
        "    print(\"Aggregation tables: party_performance_summary, state_election_summary, etc.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting data preparation...\n",
            "Original dataset shape: (91669, 45)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3193932709.py:33: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[col] = df[col].astype(str).str.lower().replace({\n",
            "/tmp/ipython-input-3193932709.py:33: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[col] = df[col].astype(str).str.lower().replace({\n",
            "/tmp/ipython-input-3193932709.py:33: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[col] = df[col].astype(str).str.lower().replace({\n",
            "/tmp/ipython-input-3193932709.py:33: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[col] = df[col].astype(str).str.lower().replace({\n",
            "/tmp/ipython-input-3193932709.py:33: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[col] = df[col].astype(str).str.lower().replace({\n",
            "/tmp/ipython-input-3193932709.py:33: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[col] = df[col].astype(str).str.lower().replace({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned dataset shape: (91669, 49)\n",
            "Missing values after cleaning:\n",
            "2274\n",
            "\n",
            "==================================================\n",
            "DATA QUALITY REPORT\n",
            "==================================================\n",
            "Total Records: 91,669\n",
            "Total Columns: 49\n",
            "Total Missing Values: 2274\n",
            "\n",
            "Column Completeness (%):\n",
            "  State_Name: 100.0%\n",
            "  Assembly_No: 100.0%\n",
            "  Constituency_No: 100.0%\n",
            "  Year: 100.0%\n",
            "  month: 100.0%\n",
            "  Poll_No: 100.0%\n",
            "  DelimID: 100.0%\n",
            "  Position: 100.0%\n",
            "  Candidate: 100.0%\n",
            "  Sex: 100.0%\n",
            "  Party: 100.0%\n",
            "  Votes: 100.0%\n",
            "  Candidate_Type: 100.0%\n",
            "  Valid_Votes: 100.0%\n",
            "  Electors: 100.0%\n",
            "  Constituency_Name: 100.0%\n",
            "  Constituency_Type: 100.0%\n",
            "  Sub_Region: 100.0%\n",
            "  N_Cand: 100.0%\n",
            "  Turnout_Percentage: 100.0%\n",
            "  Vote_Share_Percentage: 100.0%\n",
            "  Deposit_Lost: 100.0%\n",
            "  Margin: 100.0%\n",
            "  Margin_Percentage: 100.0%\n",
            "  ENOP: 100.0%\n",
            "  pid: 98.8%\n",
            "  Party_Type_TCPD: 100.0%\n",
            "  Party_ID: 100.0%\n",
            "  last_poll: 100.0%\n",
            "  Contested: 98.8%\n",
            "  Last_Party: 100.0%\n",
            "  Last_Party_ID: 100.0%\n",
            "  Last_Constituency_Name: 100.0%\n",
            "  Same_Constituency: 100.0%\n",
            "  Same_Party: 100.0%\n",
            "  No_Terms: 100.0%\n",
            "  Turncoat: 100.0%\n",
            "  Incumbent: 100.0%\n",
            "  Recontest: 100.0%\n",
            "  MyNeta_education: 100.0%\n",
            "  TCPD_Prof_Main: 100.0%\n",
            "  TCPD_Prof_Main_Desc: 100.0%\n",
            "  TCPD_Prof_Second: 100.0%\n",
            "  TCPD_Prof_Second_Desc: 100.0%\n",
            "  Election_Type: 100.0%\n",
            "  Is_Winner: 100.0%\n",
            "  Margin_Category: 100.0%\n",
            "  Experience_Level: 100.0%\n",
            "  Party_Size: 100.0%\n",
            "\n",
            "Unique States: 40\n",
            "Unique Parties: 1614\n",
            "Unique Constituencies: 946\n",
            "\n",
            "Election Years: [np.int64(1962), np.int64(1963), np.int64(1964), np.int64(1965), np.int64(1967), np.int64(1968), np.int64(1969), np.int64(1970), np.int64(1971), np.int64(1972), np.int64(1977), np.int64(1978), np.int64(1979), np.int64(1980), np.int64(1981), np.int64(1982), np.int64(1984), np.int64(1985), np.int64(1986), np.int64(1987), np.int64(1988), np.int64(1989), np.int64(1991), np.int64(1992), np.int64(1993), np.int64(1994), np.int64(1995), np.int64(1996), np.int64(1997), np.int64(1998), np.int64(1999), np.int64(2000), np.int64(2001), np.int64(2002), np.int64(2003), np.int64(2004), np.int64(2005), np.int64(2006), np.int64(2007), np.int64(2008), np.int64(2009), np.int64(2011), np.int64(2012), np.int64(2013), np.int64(2014), np.int64(2015), np.int64(2016), np.int64(2017), np.int64(2018), np.int64(2019), np.int64(2020), np.int64(2021)]\n",
            "\n",
            "Total Winners: 8,291\n",
            "Female Winners: 674\n",
            "Male Winners: 7,546\n",
            "\n",
            "Creating database schema...\n",
            "Created tables:\n",
            " - party_performance_summary\n",
            " - state_election_summary\n",
            " - candidate_experience_analysis\n",
            " - close_contest_analysis\n",
            " - election_results\n",
            " - party_dimension\n",
            " - candidate_dimension\n",
            " - constituency_dimension\n",
            "\n",
            "Sample data from main table:\n",
            "                  State_Name              Candidate Party    Votes  Position\n",
            "0  Andaman_&_Nicobar_Islands     Kuldeep Rai Sharma   INC  95308.0         1\n",
            "1  Andaman_&_Nicobar_Islands           Vishal Jolly   BJP  93901.0         2\n",
            "2  Andaman_&_Nicobar_Islands  Paritosh Kumar Haldar   IND   5341.0         3\n",
            "\n",
            "Database creation completed successfully!\n",
            "\n",
            "==================================================\n",
            "QUERY EXAMPLES\n",
            "==================================================\n",
            "\n",
            "Top 10 parties by seats won:\n",
            "    Party  seats_won   total_votes\n",
            "0     INC       2942  1.364944e+09\n",
            "1     BJP       1603  9.488584e+08\n",
            "2     CPM        370  2.232780e+08\n",
            "3  INC(I)        367  8.845586e+07\n",
            "4     BLD        295  7.806283e+07\n",
            "\n",
            "States with highest turnout:\n",
            "                             State_Name  avg_turnout  total_constituencies\n",
            "0                           Lakshadweep    82.528723                     3\n",
            "1  Dadra & Nagar Haveli And Daman & Diu    76.590000                     1\n",
            "2                               Tripura    75.784404                     3\n",
            "3                              Nagaland    75.147333                     1\n",
            "4                            Puducherry    74.597312                     2\n",
            "\n",
            "Close contests by state:\n",
            "                  State_Name  Margin_Category  contest_count\n",
            "0  Andaman_&_Nicobar_Islands     Large Margin              3\n",
            "1  Andaman_&_Nicobar_Islands  Moderate Margin              1\n",
            "2  Andaman_&_Nicobar_Islands    Close Contest              1\n",
            "3             Andhra_Pradesh     Large Margin             61\n",
            "4             Andhra_Pradesh  Moderate Margin             56\n",
            "\n",
            "Candidate experience analysis:\n",
            "  Experience_Level  candidate_count  winners  win_rate\n",
            "0           Senior              300      230     76.67\n",
            "1          Veteran             2369     1608     67.88\n",
            "2      Experienced             9513     6453     67.83\n",
            "3              New            79487        0      0.00\n",
            "\n",
            "==================================================\n",
            "DATA PREPARATION COMPLETED SUCCESSFULLY!\n",
            "==================================================\n",
            "Database file: election_data.db\n",
            "Main table: election_results\n",
            "Dimension tables: party_dimension, candidate_dimension, constituency_dimension\n",
            "Aggregation tables: party_performance_summary, state_election_summary, etc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Additional Analysis and Export Code**"
      ],
      "metadata": {
        "id": "TxJGOjZY2Lvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Additional utility functions for data analysis\n",
        "def export_cleaned_data():\n",
        "    \"\"\"\n",
        "    Export cleaned data to CSV for external use\n",
        "    \"\"\"\n",
        "    df = pd.read_csv('All_States_GE.csv', low_memory=False)\n",
        "\n",
        "    # Apply the same cleaning logic\n",
        "    cleaned_df = clean_and_prepare_data()\n",
        "\n",
        "    # Export to CSV\n",
        "    cleaned_df.to_csv('cleaned_election_data.csv', index=False)\n",
        "    print(\"Cleaned data exported to 'cleaned_election_data.csv'\")\n",
        "\n",
        "def create_advanced_queries():\n",
        "    \"\"\"\n",
        "    Create more advanced analytical queries\n",
        "    \"\"\"\n",
        "    conn = sqlite3.connect('election_data.db')\n",
        "\n",
        "    advanced_queries = {\n",
        "        \"Party performance by state\": \"\"\"\n",
        "            SELECT\n",
        "                e.State_Name,\n",
        "                e.Party,\n",
        "                COUNT(*) as candidates,\n",
        "                SUM(CASE WHEN e.Position = 1 THEN 1 ELSE 0 END) as winners,\n",
        "                AVG(e.Vote_Share_Percentage) as avg_vote_share\n",
        "            FROM election_results e\n",
        "            GROUP BY e.State_Name, e.Party\n",
        "            HAVING winners > 0\n",
        "            ORDER BY e.State_Name, winners DESC\n",
        "            \"\"\",\n",
        "\n",
        "        \"Incumbent performance analysis\": \"\"\"\n",
        "            SELECT\n",
        "                Incumbent,\n",
        "                COUNT(*) as candidates,\n",
        "                SUM(CASE WHEN Position = 1 THEN 1 ELSE 0 END) as winners,\n",
        "                ROUND(100.0 * SUM(CASE WHEN Position = 1 THEN 1 ELSE 0 END) / COUNT(*), 2) as win_rate\n",
        "            FROM election_results\n",
        "            GROUP BY Incumbent\n",
        "            \"\"\",\n",
        "\n",
        "        \"Gender-wise performance\": \"\"\"\n",
        "            SELECT\n",
        "                Sex,\n",
        "                COUNT(*) as candidates,\n",
        "                SUM(CASE WHEN Position = 1 THEN 1 ELSE 0 END) as winners,\n",
        "                AVG(Vote_Share_Percentage) as avg_vote_share,\n",
        "                ROUND(100.0 * SUM(CASE WHEN Position = 1 THEN 1 ELSE 0 END) / COUNT(*), 2) as win_rate\n",
        "            FROM election_results\n",
        "            GROUP BY Sex\n",
        "            \"\"\",\n",
        "\n",
        "        \"Top constituencies by voter turnout\": \"\"\"\n",
        "            SELECT\n",
        "                State_Name,\n",
        "                Constituency_Name,\n",
        "                MAX(Turnout_Percentage) as max_turnout,\n",
        "                MAX(Electors) as total_electors,\n",
        "                MAX(Valid_Votes) as total_votes\n",
        "            FROM election_results\n",
        "            GROUP BY State_Name, Constituency_Name\n",
        "            ORDER BY max_turnout DESC\n",
        "            LIMIT 15\n",
        "            \"\"\"\n",
        "    }\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"ADVANCED ANALYTICAL QUERIES\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    for query_name, query in advanced_queries.items():\n",
        "        print(f\"\\n{query_name}:\")\n",
        "        try:\n",
        "            result = pd.read_sql(query, conn)\n",
        "            print(result.head(8))\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "# Run additional functions if needed\n",
        "# export_cleaned_data()\n",
        "# create_advanced_queries()"
      ],
      "metadata": {
        "id": "wei-c8f72Jrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Database Connection and Management Code**"
      ],
      "metadata": {
        "id": "zpKlJft_2nvn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ElectionDatabaseManager:\n",
        "    \"\"\"\n",
        "    Class to manage election database operations\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, db_path='election_data.db'):\n",
        "        self.db_path = db_path\n",
        "        self.conn = None\n",
        "\n",
        "    def connect(self):\n",
        "        \"\"\"Connect to the database\"\"\"\n",
        "        self.conn = sqlite3.connect(self.db_path)\n",
        "        return self.conn\n",
        "\n",
        "    def disconnect(self):\n",
        "        \"\"\"Disconnect from database\"\"\"\n",
        "        if self.conn:\n",
        "            self.conn.close()\n",
        "\n",
        "    def get_table_info(self, table_name):\n",
        "        \"\"\"Get schema information for a table\"\"\"\n",
        "        conn = self.connect()\n",
        "        query = f\"PRAGMA table_info({table_name})\"\n",
        "        schema = pd.read_sql(query, conn)\n",
        "        self.disconnect()\n",
        "        return schema\n",
        "\n",
        "    def get_table_stats(self):\n",
        "        \"\"\"Get statistics for all tables\"\"\"\n",
        "        conn = self.connect()\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        # Get all tables\n",
        "        cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "        tables = cursor.fetchall()\n",
        "\n",
        "        stats = {}\n",
        "        for table in tables:\n",
        "            table_name = table[0]\n",
        "            cursor.execute(f\"SELECT COUNT(*) FROM {table_name}\")\n",
        "            row_count = cursor.fetchone()[0]\n",
        "            stats[table_name] = row_count\n",
        "\n",
        "        self.disconnect()\n",
        "        return stats\n",
        "\n",
        "    def custom_query(self, query, params=None):\n",
        "        \"\"\"Execute custom query\"\"\"\n",
        "        conn = self.connect()\n",
        "        try:\n",
        "            if params:\n",
        "                result = pd.read_sql(query, conn, params=params)\n",
        "            else:\n",
        "                result = pd.read_sql(query, conn)\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            print(f\"Query error: {e}\")\n",
        "            return None\n",
        "        finally:\n",
        "            self.disconnect()\n",
        "\n",
        "# Usage example:\n",
        "def demonstrate_database_usage():\n",
        "    \"\"\"\n",
        "    Demonstrate how to use the database manager\n",
        "    \"\"\"\n",
        "    db_manager = ElectionDatabaseManager()\n",
        "\n",
        "    print(\"Database Statistics:\")\n",
        "    stats = db_manager.get_table_stats()\n",
        "    for table, count in stats.items():\n",
        "        print(f\"  {table}: {count:,} rows\")\n",
        "\n",
        "    print(\"\\nMain Table Schema:\")\n",
        "    schema = db_manager.get_table_info('election_results')\n",
        "    print(schema[['name', 'type']].head(10))\n",
        "\n",
        "    # Example custom query\n",
        "    custom_query = \"\"\"\n",
        "        SELECT\n",
        "            State_Name,\n",
        "            COUNT(*) as total_candidates,\n",
        "            SUM(CASE WHEN Sex = 'F' THEN 1 ELSE 0 END) as female_candidates,\n",
        "            ROUND(100.0 * SUM(CASE WHEN Sex = 'F' THEN 1 ELSE 0 END) / COUNT(*), 2) as female_percentage\n",
        "        FROM election_results\n",
        "        GROUP BY State_Name\n",
        "        ORDER BY female_percentage DESC\n",
        "        LIMIT 10\n",
        "        \"\"\"\n",
        "\n",
        "    print(\"\\nGender Diversity by State:\")\n",
        "    result = db_manager.custom_query(custom_query)\n",
        "    print(result)\n",
        "\n",
        "# Uncomment to run demonstration\n",
        "# demonstrate_database_usage()"
      ],
      "metadata": {
        "id": "mne9-3OR2pdw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}